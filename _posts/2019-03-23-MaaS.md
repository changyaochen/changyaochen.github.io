---
layout: single
title:  "Model as a Service through Flask"
date:   2019-03-23 12:00:01 -0600
published: false
tag: [python]
excerpt: How to speed up the time from between model development to model deployment.
toc: true
header:
  teaser: /assets/images/maas_teaser.png
---
The purpose of any model can only be fulfilled if it is put to use by other people, as soon as possible. Namely, if one can shorten the time between the model *development* and model *deployment*, it would help to validate (or invalidate) his / her team's value in the organization. However, deploying a model (**i.e.**, put it to production) can be a long yet tedious process, especially without a strong engineering support.

## What does the client want
Often time, the end users of our models are other stakeholder within the organization, who simply would like to know the prediction of your model, on a new input. Think a mortgage application: the applicant walks into the bank, and the loan officier would like to know the her / his probability of default, given some attributes of both the applicant and the intended loan. In this case, the officier should be able to quickly put those information to the model, and get the result. 

In the end, the client only needs to pass the essential information, such as `{'age': 35, 'gender': 'male', ...}` to the model, and expecting something like `{'prediction': 0.02}`. Everything else should be handled by the infrastructure and the model behind. Given such design pattern, it is hard not to use the [RESTful](https://en.wikipedia.org/wiki/Representational_state_transfer) API service.

## A server to meet the client's need
If there is an internal website that is available to the loan officer, then he / she can simply just send all the information, nested as a `json` string, as an HTTP POST request to the server. Once the server receives the request, it will parses the `json` string, invoke the appropriate model, make the prediction, and return the result to the POST request. Done!

It all sounds great, but how much effort is needed to actually make this website? It turns out, not so difficult, at least for a working prototype. Thanks to [`Flask`](https://en.wikipedia.org/wiki/Flask_(web_framework)), one can deployment a model in this fashion just in minutes. 

## Hello world server
Nothing works better than a hello-world example. First let's make a dedicated folder (`model_server`) for this purpose, with the following structure.

```
── model_server
    ├── server.py
    ├── utils.py
    └── models
        ├── model1.pkl
        ...
```
We have trained and pickled a model named `model1.pkl` and put it under the `/models` folder. The `utils.py` will contain some helper functions, and the main effort will be in the `server.py` file. 

~~~py
from flask import Flask, jsonify, request, abort
from utils import load_pkl_model, check_payload, get_precition

app = Flask(__name__)
MODEL_NAME = './models/model1.pkl'

@app.route('/')
def home():
    """This function just responds to the browser URL.
    """
    return "Home page"
    
@app.route('/api', methods=['POST', 'GET'])
def api():
    """This is the endpoint of api calls."""

    # let's load the model first
    model = load_pkl_model(MODEL_NAME)

    if request.method == 'POST':
        try:  # we want json
            payload = request.get_json(force=True)  # convert it to dict
            data = payload['data']  # `data` is a dict
        except Exception as e:
            print(e)
            abort(404)

        # payload received, let's turn it to proper format
        inputs = check_payload(data)  # `inputs` is a list 

        # combine the input and model
        pred = get_precition(model, inputs)  # `pred` is a dict

        return jsonify(pred)

    else:  # GET, print some info about the model
        return jsonify({
            'model_name': MODEL_NAME,
            })
            
if __name__ == '__main__':
    app.run(debug=True, port=5050)
~~~
The code should be pretty straightforward, where the meat is in the `api()` function. We simply carry out a procedural process to: 1) load the model, 2) process the received input, 3) apply the input to the model. 

The devil is in the detail, and I conveniently brush it under `utils.py`. In any case, we are ready to start the server! In the terminal, simply go into `model_server` folder, and type:

~~~sh
$ python server.py
~~~
Lo and behold, `Flask` will do its magic, and we have a server running at `http://127.0.0.1:5050`. 

## Making an API call
Now we have the server ready, let the client make the call. 

~~~py
import request

payload = {
    "data": {
        "feature_1": 1.0, 
        "feature_2": 0.5, 
        }
}

url = 'http://127.0.0.1:5050/api'  # if you are running it locally
r = requests.post(url, json=payload)
r.json()  # it should be the `pred` variable defined in `server.py`
~~~




