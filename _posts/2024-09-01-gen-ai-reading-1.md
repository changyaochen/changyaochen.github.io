---
layout: single
title:  "Notes for Generative AI learning, part 1"
date:   2024-09-05 12:00:00 -0600
published: false
tag: [machine learning]
toc: true
toc_sticky: true
excerpt: "Scratch notes when reading the O'Reilly book of 'Generative Deep Learning, 2nd Edition'"
header:
  teaser: assets/images/transformer_architecture.png
---

### Chapter 1 and 2

Mostly introductory to generative models and neural networks. Nothing very new to me.

### Chapter 3. Variational Autoencoders (VAEs)

A simple autoencoder is a neural network that takes an input and maps it to
a **fixed** point in the latent space (encoder), and then from this point, we
try to create (that is, reconstruct) the input (_i.e._, an image).


How to create an image from a latent vector? With `tensorflow/keras`, we can use
either the `Conv2DTranspose` layer or the `UpSampling2D` layer. The idea is the same:
we first increase the size of the 2D space, by either filling with zeros or repeating
the nearest pixel. With the enlarged 2D space, we then apply the convolutional operation
with stride of 1.

The key idea of VAE is instead of mapping an input to a fixed point in the latent space,
we map it to a (standard normal) distribution in the latent space.

The model parameters now will also include the parameters of the distribution in the latent space,
for example, if the latent space is 100-dimensional and we want to use a normal distribution,
we will have 200 parameters to learn: 2 for each dimension. Accordingly, the loss function
will include both the reconstruction loss and the Kullbackâ€“Leibler (KL) divergence loss.
The latter is to measure the similarity between the learned distribution and a standard normal distribution:
we also want to minimize this loss.
A good explanation of the intuition can be found [here](https://stats.stackexchange.com/a/395032)
and the derivation between two Normal distributions can be found [here](https://stats.stackexchange.com/q/7440).

### Chapter 4, Generative Adversarial Networks

When training the generator, why do we set the label as "1", as if the generated image is real?
Note that in this phase, we assume we have a perfect discriminator which outputs the probability of the image being real.
Among the images generated by the generator, if by chance we create a truly real image, this will be
correctly identified by the discriminator as real (giving a high probability), therefore, we want to
reward such a situation by setting the label as "1" and use the binary cross-entropy as the loss function.

At the end of the day, we want the generator to generate images that are indistinguishable from the real images.
